"""baseline schema

Revision ID: b86b67add848
Revises: 
Create Date: 2026-02-21 11:01:46.303770

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'b86b67add848'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('artifact_data',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('total_size', sa.BigInteger(), nullable=False),
    sa.Column('is_dir', sa.Boolean(), nullable=False),
    sa.Column('hash', sa.String(length=255), nullable=False),
    sa.Column('uri', sa.String(length=255), nullable=True),
    sa.Column('value', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('container_execution',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('status', sa.Enum('INVALID', 'UNINITIALIZED', 'QUEUED', 'WAITING_FOR_UPSTREAM', 'PENDING', 'RUNNING', 'SUCCEEDED', 'FAILED', 'SYSTEM_ERROR', 'CANCELLING', 'CANCELLED', 'SKIPPED', name='containerexecutionstatus'), nullable=False),
    sa.Column('last_processed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('ended_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('exit_code', sa.Integer(), nullable=True),
    sa.Column('launcher_data', sa.JSON(), nullable=True),
    sa.Column('input_artifact_data_map', sa.JSON(), nullable=True),
    sa.Column('output_artifact_data_map', sa.JSON(), nullable=True),
    sa.Column('log_uri', sa.String(length=255), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('container_execution', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_container_execution_status'), ['status'], unique=False)
        batch_op.create_index('ix_container_execution_status_last_processed_at', ['status', 'last_processed_at'], unique=False)

    op.create_table('secret',
    sa.Column('user_id', sa.String(length=255), nullable=False),
    sa.Column('secret_name', sa.String(length=255), nullable=False),
    sa.Column('secret_value', sa.String(length=255), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('description', sa.String(length=255), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('user_id', 'secret_name')
    )
    with op.batch_alter_table('secret', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_secret_user_id'), ['user_id'], unique=False)

    op.create_table('execution_node',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('task_spec', sa.JSON(), nullable=False),
    sa.Column('parent_execution_id', sa.String(length=255), nullable=True),
    sa.Column('task_id_in_parent_execution', sa.String(length=255), nullable=True),
    sa.Column('container_execution_id', sa.String(length=255), nullable=True),
    sa.Column('container_execution_status', sa.Enum('INVALID', 'UNINITIALIZED', 'QUEUED', 'WAITING_FOR_UPSTREAM', 'PENDING', 'RUNNING', 'SUCCEEDED', 'FAILED', 'SYSTEM_ERROR', 'CANCELLING', 'CANCELLED', 'SKIPPED', name='containerexecutionstatus'), nullable=True),
    sa.Column('container_execution_cache_key', sa.String(length=255), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['container_execution_id'], ['container_execution.id'], ),
    sa.ForeignKeyConstraint(['parent_execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('execution_node', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_execution_node_container_execution_cache_key'), ['container_execution_cache_key'], unique=False)
        batch_op.create_index(batch_op.f('ix_execution_node_container_execution_status'), ['container_execution_status'], unique=False)

    op.create_table('artifact_node',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('had_data_in_past', sa.Boolean(), nullable=False),
    sa.Column('may_have_data_in_future', sa.Boolean(), nullable=False),
    sa.Column('type_name', sa.String(length=255), nullable=True),
    sa.Column('type_properties', sa.JSON(), nullable=True),
    sa.Column('producer_execution_id', sa.String(length=255), nullable=True),
    sa.Column('producer_output_name', sa.String(length=255), nullable=True),
    sa.Column('artifact_data_id', sa.String(length=255), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['artifact_data_id'], ['artifact_data.id'], ),
    sa.ForeignKeyConstraint(['producer_execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('execution_ancestor',
    sa.Column('ancestor_execution_id', sa.String(length=255), nullable=False),
    sa.Column('execution_id', sa.String(length=255), nullable=False),
    sa.ForeignKeyConstraint(['ancestor_execution_id'], ['execution_node.id'], ),
    sa.ForeignKeyConstraint(['execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('ancestor_execution_id', 'execution_id')
    )
    op.create_table('pipeline_run',
    sa.Column('id', sa.String(length=255), nullable=False),
    sa.Column('root_execution_id', sa.String(length=255), nullable=False),
    sa.Column('annotations', sa.JSON(), nullable=True),
    sa.Column('created_by', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('parent_pipeline_id', sa.String(length=255), nullable=True),
    sa.Column('extra_data', sa.JSON(), nullable=True),
    sa.Column('pipeline_name', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['root_execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('pipeline_run', schema=None) as batch_op:
        batch_op.create_index('ix_pipeline_run_created_at_desc', [sa.literal_column('created_at DESC')], unique=False)
        batch_op.create_index('ix_pipeline_run_created_by_created_at_desc', ['created_by', sa.literal_column('created_at DESC')], unique=False)
        batch_op.create_index('ix_pipeline_run_pipeline_name', ['pipeline_name'], unique=False)

    op.create_table('input_artifact_link',
    sa.Column('execution_id', sa.String(length=255), nullable=False),
    sa.Column('input_name', sa.String(length=255), nullable=False),
    sa.Column('artifact_id', sa.String(length=255), nullable=False),
    sa.ForeignKeyConstraint(['artifact_id'], ['artifact_node.id'], ),
    sa.ForeignKeyConstraint(['execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('execution_id', 'input_name')
    )
    op.create_table('output_artifact_link',
    sa.Column('execution_id', sa.String(length=255), nullable=False),
    sa.Column('output_name', sa.String(length=255), nullable=False),
    sa.Column('artifact_id', sa.String(length=255), nullable=False),
    sa.ForeignKeyConstraint(['artifact_id'], ['artifact_node.id'], ),
    sa.ForeignKeyConstraint(['execution_id'], ['execution_node.id'], ),
    sa.PrimaryKeyConstraint('execution_id', 'output_name')
    )
    op.create_table('pipeline_run_annotation',
    sa.Column('pipeline_run_id', sa.String(length=255), nullable=False),
    sa.Column('key', sa.String(length=255), nullable=False),
    sa.Column('value', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['pipeline_run_id'], ['pipeline_run.id'], ),
    sa.PrimaryKeyConstraint('pipeline_run_id', 'key')
    )
    with op.batch_alter_table('pipeline_run_annotation', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_pipeline_run_annotation_pipeline_run_id'), ['pipeline_run_id'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('pipeline_run_annotation', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_pipeline_run_annotation_pipeline_run_id'))

    op.drop_table('pipeline_run_annotation')
    op.drop_table('output_artifact_link')
    op.drop_table('input_artifact_link')
    with op.batch_alter_table('pipeline_run', schema=None) as batch_op:
        batch_op.drop_index('ix_pipeline_run_pipeline_name')
        batch_op.drop_index('ix_pipeline_run_created_by_created_at_desc')
        batch_op.drop_index('ix_pipeline_run_created_at_desc')

    op.drop_table('pipeline_run')
    op.drop_table('execution_ancestor')
    op.drop_table('artifact_node')
    with op.batch_alter_table('execution_node', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_execution_node_container_execution_status'))
        batch_op.drop_index(batch_op.f('ix_execution_node_container_execution_cache_key'))

    op.drop_table('execution_node')
    with op.batch_alter_table('secret', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_secret_user_id'))

    op.drop_table('secret')
    with op.batch_alter_table('container_execution', schema=None) as batch_op:
        batch_op.drop_index('ix_container_execution_status_last_processed_at')
        batch_op.drop_index(batch_op.f('ix_container_execution_status'))

    op.drop_table('container_execution')
    op.drop_table('artifact_data')
    # ### end Alembic commands ###
